# Agent Server Configuration
# Copy this file to .env and fill in your values

# ===== LLM Provider Configuration =====

# Ollama Configuration
# Host for your local Ollama instance
OLLAMA_HOST=localhost:11434

# Anthropic Configuration
# Get your API key from: https://console.anthropic.com/
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# ===== Logging =====
# Log level: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO
